{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "taken-mayor",
   "metadata": {},
   "source": [
    "## __GAN from scratch__\n",
    "____\n",
    "### __Game plan:__ \n",
    "1) __Dataset -> MNIST__\n",
    "\n",
    "2) __Tips:__ \n",
    "* [x] Change value of pixels to be between -1 or 1 and float32 type\n",
    "* [x] Smoothing labels to 0.9 - 1.0 for real images and 0 - 0.1 for fake to train the discrimator\n",
    "* [x] Adam's momentum parameter set to 0.5 improves stability \n",
    "* [x] Noise labels with 5% probability\n",
    "* [x] Gaussian distribution instead of uniform distribution\n",
    "* [x] Batch Normalization \n",
    "* [x] Conv2D Transpose \n",
    "\n",
    "3) __Hyperparameters:__ \n",
    "* Batch size -> 32 - 256\n",
    "* Epochs -> 1000\n",
    "* Optimizer\n",
    "    * Adam with lr = 2e-4\n",
    "* Network\n",
    "    * Discriminator -> 128, 64, 32, 1\n",
    "    * Generator -> 32, 64, 128, 784(28*28)\n",
    "    * DCGAN: \n",
    "        * G : 1024, 512, 256, 128\n",
    "        * D : 128, 256, 512, 1024\n",
    "* Layers\n",
    "    * Dropout -> 0.3, default for Discrimnator\n",
    "    * Batch Normalization \n",
    "* Activation function\n",
    "    * LeakyRelu for all hidden layers -> alpha = 0.2 for Discrimnator\n",
    "    * Tanh for output layer for generator -> scales output to -1,1 instead of 0,1\n",
    "    * Relu for generator -> NO \n",
    "* Loss function\n",
    "    * Discrimator -> 0.5(l_real + l_fake)\n",
    "    * Generator -> target value is 1 for each fake\n",
    "* Latent space size z = 100 or 128\n",
    "\n",
    "\n",
    "4) __Traning:__ \n",
    "* Discrimator -> freeze generator \n",
    "    * Train on batch of real examples with labels  \n",
    "    * Generate batch of fake examples with labels and train on them\n",
    "    * Backprop and add both loss functions \n",
    "* Generator -> freeze discriminator\n",
    "    * Batch of fake images with labels  \n",
    "    * Discrimnator Loss on fake images\n",
    "    * Backprop of generator model using discrimator loss \n",
    "\n",
    "5) __Graphs:__\n",
    "* Loss function \n",
    "* Tracing propability of detecting whether is real or fake for discriminator \n",
    "* TESTS: \n",
    "    * No dense at the output -> lower resolution, almost black\n",
    "    * 2 Dense output layers -> a lot of noice, almost white images \n",
    "    * No dropout layers in Discriminator -> lower resolution\n",
    "    * ReLU in Generator -> lower resolution, lots of noice\n",
    "    * G : {128, 256}, D: {128, 256} instead of G: {128, 64}, D: {64, 128} \n",
    "    * Batch Normalization only in Generator -> sharper, clean, better resolution\n",
    "    * No Dense layer in Generator -> white images, lots of noise\n",
    "    * Both Discriminator and Generator should have the same networks\n",
    "    * Twisting: \n",
    "        * Batch -> 32, __64__, 128, __256__\n",
    "        * Latent space -> 100, 128\n",
    "        * Optimizer -> either 1e-4 or 2e-4\n",
    "        * \n",
    "    \n",
    "6) __References:__ \n",
    "* https://github.com/tdrussell/IllustrationGAN\n",
    "* https://towardsdatascience.com/gan-ways-to-improve-gan-performance-acf37f9f59b\n",
    "* https://aylien.com/blog/introduction-generative-adversarial-networks-code-tensorflow\n",
    "* ALL MININBATCH DISCRIMINATION ABOVE ^\n",
    "* https://stackoverflow.com/questions/60553795/random-noise-for-gan -> random noise \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mounted-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dropout, BatchNormalization as BN, LeakyReLU, Flatten, Dense, Reshape, ReLU, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ready-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit  : 1, Occurance : 6742\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [np.count_nonzero(label == i) for i in range(0,10)]\n",
    "plt.bar([i for i in range(0,10)], y, width = 0.5)\n",
    "plt.xlabel('Digits')\n",
    "plt.ylabel('Occurance')\n",
    "plt.xlim(-0.5,9.5)\n",
    "plt.xticks([i for i in range(0,10)])\n",
    "print('Digit  : {}, Occurance : {}'.format(np.argmax(y), np.max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "modular-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "(real, label), (_, _) = mnist.load_data()\n",
    "dataset = (real[np.where(label == 8)] - 127.5).astype(np.float32) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "photographic-constant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5851, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "accompanied-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, lr, input_shape):\n",
    "        self.lr = lr\n",
    "        self.input_shape = input_shape\n",
    "        self.d = self.model() \n",
    "        \n",
    "    def model(self):\n",
    "        Model = Sequential()\n",
    "        Model.add(Conv2D(filters = 32, kernel_size = (5,5), strides = (1,1), padding = 'same', input_shape = self.input_shape))\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "        Model.add(Dropout(0.3))        \n",
    "        \n",
    "        Model.add(Conv2D(filters = 64, kernel_size = (5,5), strides = (2,2), padding = 'same'))\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "        Model.add(Dropout(0.3))\n",
    "        \n",
    "        Model.add(Conv2D(filters = 128, kernel_size = (5,5), strides = (2,2), padding = 'same'))\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "        Model.add(Dropout(0.3))\n",
    "    \n",
    "    \n",
    "        Model.add(Flatten())\n",
    "        \n",
    "        Model.add(Dense(1, activation = 'sigmoid'))\n",
    "        Model.compile(optimizer = Adam(lr = self.lr, beta_1 = 0.5), loss = 'binary_crossentropy')\n",
    "        \n",
    "        print(Model.summary())\n",
    "\n",
    "        return Model\n",
    "    \n",
    "class Generator:\n",
    "    def __init__(self, lr, input_shape, latent_dim):\n",
    "        self.lr = lr\n",
    "        self.latent_dim = latent_dim \n",
    "        self.output_shape = input_shape\n",
    "        self.g = self.model()\n",
    "        \n",
    "    def model(self):\n",
    "        Model = Sequential()\n",
    "        Model.add(Dense(7*7*self.latent_dim, input_dim = self.latent_dim))\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "        \n",
    "        Model.add(Reshape((7,7,self.latent_dim)))\n",
    "        Model.add(Conv2DTranspose(128, kernel_size = (5,5), strides = (2,2), padding = 'same'))\n",
    "        Model.add(BN())\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "\n",
    "        Model.add(Conv2DTranspose(64, kernel_size = (5,5), strides = (2,2), padding = 'same'))\n",
    "        Model.add(BN())\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "\n",
    "        Model.add(Conv2DTranspose(32, kernel_size = (5,5), strides = (1,1), padding = 'same'))\n",
    "        Model.add(BN())\n",
    "        Model.add(LeakyReLU(alpha = 0.2))\n",
    "\n",
    "        Model.add(Conv2DTranspose(1, kernel_size = (5,5), padding = 'same', activation = 'tanh'))   \n",
    "        Model.add(Flatten())\n",
    "        Model.add(Reshape(self.output_shape))\n",
    "        \n",
    "        print(Model.summary())\n",
    "        \n",
    "        return Model\n",
    "    \n",
    "class GAN:\n",
    "    def __init__(self, dataset, epochs = 1000, batch = 64, latent_dim = 100, lr = 2e-4):\n",
    "        self.epochs = epochs \n",
    "        self.batch = batch \n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr \n",
    "        self.dataset = dataset.reshape(*dataset.shape, 1)\n",
    "        self.input_size = (self.dataset[0].shape[0], self.dataset[0].shape[1], 1)\n",
    "        self.half_batch = self.batch // 2\n",
    "        \n",
    "        \n",
    "        self.D = Discriminator(self.lr, self.input_size).d\n",
    "        self.G = Generator(self.lr, self.input_size, self.latent_dim).g\n",
    "        self.GAN_model = self.gan_model()\n",
    "        \n",
    "        self.DLoss = []\n",
    "        self.GLoss = []\n",
    "        self.images = self.stack()\n",
    "        self.real = []\n",
    "        self.fake = []\n",
    "        self.folder = 'BN'\n",
    "        self.structure = '32x64x128_more_epochs'\n",
    "        \n",
    "    def gan_model(self):\n",
    "        self.D.trainable = False\n",
    "        \n",
    "        Model = Sequential()\n",
    "        Model.add(self.G)\n",
    "        Model.add(self.D)\n",
    "        Model.compile(optimizer = Adam(lr = self.lr, beta_1 = 0.5), loss = 'binary_crossentropy')\n",
    "        return Model \n",
    "    \n",
    "    def z(self,batch):\n",
    "        return np.random.uniform(-1,1,(batch,self.latent_dim)).reshape(batch,1,1,self.latent_dim)\n",
    "    \n",
    "    def stack(self, size = 15): \n",
    "        imgs = self.G.predict(self.z(size))\n",
    "        stacked = imgs[0]\n",
    "        for i in range(1,size): \n",
    "            stacked = np.vstack((stacked, imgs[i]))\n",
    "            \n",
    "        return stacked\n",
    "    \n",
    "    def loss_graph(self, epoch):\n",
    "        x = [i for i in range(len(self.GLoss))]\n",
    "        plt.plot(x,self.GLoss, color = 'b', label = 'Generator')\n",
    "        plt.plot(x,self.DLoss, color = 'y', label = 'Discriminator')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig(r'GAN/{}/Loss{}_{}.png'.format(self.folder,epoch, self.structure),dpi = 400)\n",
    "        plt.imsave(r'GAN/{}/test{}_{}.png'.format(self.folder, epoch, self.structure),self.images.reshape(self.images.shape[0],self.images.shape[1]), cmap = 'gray', dpi = 400)\n",
    "\n",
    "    def train(self): \n",
    "        for epoch in tqdm(range(1, self.epochs+1), ascii = True, unit = 'Epoch'):\n",
    "        \n",
    "#            if np.random.random() > 0:\n",
    "            real_labels = np.random.uniform(0.9,1,self.half_batch).reshape(self.half_batch,1)\n",
    "            fake_labels = np.random.uniform(0,0.1,self.half_batch).reshape(self.half_batch,1)\n",
    "            '''\n",
    "            else:\n",
    "                real_labels = np.random.uniform(0,0.1,self.half_batch).reshape(self.half_batch,1)\n",
    "                fake_labels = np.random.uniform(0.9,1,self.half_batch).reshape(self.half_batch,1)\n",
    "            '''\n",
    "            real_imgs = self.dataset[np.random.randint(0,len(self.dataset), self.half_batch)]\n",
    "            real_loss = self.D.train_on_batch(real_imgs,real_labels)\n",
    "            \n",
    "            fake_imgs = self.G.predict(self.z(self.half_batch))\n",
    "            fake_loss = self.D.train_on_batch(fake_imgs, fake_labels)\n",
    "            \n",
    "            DL = 0.5 * (real_loss + fake_loss)\n",
    "            self.DLoss.append(DL)\n",
    "            \n",
    "            #-----------------------------------------------------#\n",
    "            \n",
    "            noise = self.z(self.batch)\n",
    "            labels = np.random.uniform(0.9,1,self.batch)\n",
    "            GL = self.GAN_model.train_on_batch(noise,labels)\n",
    "            self.GLoss.append(GL)\n",
    "            \n",
    "            #-----------------------------------------------------#\n",
    "            \n",
    "            if epoch%(self.epochs//50) == 0:\n",
    "                self.images = np.hstack((self.images,self.stack()))\n",
    "                if epoch > self.epochs // 2: \n",
    "                    self.G.save(r'GAN/BN/Models/{}_model_{}.h5'.format(epoch, self.structure))\n",
    "                \n",
    "            if epoch%(self.epochs//2) == 0:\n",
    "                self.loss_graph(epoch)\n",
    "                \n",
    "                \n",
    "        self.G.save(r'GAN/{}/Models/model_{}.h5'.format(self.folder,self.structure))            \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-ethernet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_141 (Conv2D)          (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_384 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_142 (Conv2D)          (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_385 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_143 (Conv2D)          (None, 7, 7, 128)         204928    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_386 (LeakyReLU)  (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_106 (Flatten)        (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1)                 6273      \n",
      "=================================================================\n",
      "Total params: 263,297\n",
      "Trainable params: 263,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_145\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_161 (Dense)            (None, 4900)              494900    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_387 (LeakyReLU)  (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "reshape_106 (Reshape)        (None, 7, 7, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_192 (Conv2D (None, 14, 14, 128)       320128    \n",
      "_________________________________________________________________\n",
      "batch_normalization_174 (Bat (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_388 (LeakyReLU)  (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_193 (Conv2D (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_175 (Bat (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_389 (LeakyReLU)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_194 (Conv2D (None, 28, 28, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_176 (Bat (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_390 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_195 (Conv2D (None, 28, 28, 1)         801       \n",
      "_________________________________________________________________\n",
      "flatten_107 (Flatten)        (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "reshape_107 (Reshape)        (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,072,821\n",
      "Trainable params: 1,072,373\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='dense_161_input'), name='dense_161_input', description=\"created by layer 'dense_161_input'\"), but it was called on an input with incompatible shape (None, 1, 1, 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                      | 0/5000 [00:00<?, ?Epoch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='dense_161_input'), name='dense_161_input', description=\"created by layer 'dense_161_input'\"), but it was called on an input with incompatible shape (32, 1, 1, 100).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='sequential_145_input'), name='sequential_145_input', description=\"created by layer 'sequential_145_input'\"), but it was called on an input with incompatible shape (64, 1, 1, 100).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='dense_161_input'), name='dense_161_input', description=\"created by layer 'dense_161_input'\"), but it was called on an input with incompatible shape (64, 1, 1, 100).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='sequential_145_input'), name='sequential_145_input', description=\"created by layer 'sequential_145_input'\"), but it was called on an input with incompatible shape (64, 1, 1, 100).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 100) for input KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name='dense_161_input'), name='dense_161_input', description=\"created by layer 'dense_161_input'\"), but it was called on an input with incompatible shape (64, 1, 1, 100).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|###################################################################9     | 4652/5000 [1:09:16<05:10,  1.12Epoch/s]"
     ]
    }
   ],
   "source": [
    "gan = GAN(dataset, epochs = 5000, batch = 64)\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "threatened-baseball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(gan.G, r'GAN/Generator.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
